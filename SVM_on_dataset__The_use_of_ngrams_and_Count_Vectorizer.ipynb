{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM on dataset_ The use of ngrams and Count_Vectorizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvQFWmMdRxZA",
        "outputId": "87edf433-9425-4bba-d60c-d43a17b51018"
      },
      "source": [
        "  import nltk\n",
        "  nltk.download('punkt')\n",
        "  nltk.download('stopwords')\n",
        "  from nltk.corpus import wordnet as wn\n",
        "  import sklearn\n",
        "  import os\n",
        "  import re\n",
        "  import pandas as pd\n",
        "  import math\n",
        "  import collections as cl\n",
        "  import scipy as sp\n",
        "  import numpy as np\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgRaQ4TBSB5T"
      },
      "source": [
        "from nltk.corpus.reader import wordnet\n",
        "# Uploading the file\n",
        "#my_file = open(\"sentences news.csv\", \"rt\") # open .txt for reading text\n",
        "contents= pd.read_csv('sentences news.csv')       # read the entire file to string\n",
        "contents\n",
        "\n",
        "#Cleaning the Text\n",
        "\n",
        "# Below the code for removal of meta-deta\n",
        "import re \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer  # For Steming the word\n",
        "from nltk.stem import WordNetLemmatizer # It's an Word Limitizer\n",
        "\n",
        "# Now Create Objects for cleaning Purposes\n",
        "\n",
        "\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LoiDfe8SXt6"
      },
      "source": [
        "#Creating the Bag of Words\n",
        "#Count Vectorization\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# N-Grams, Implementation of Bi Grams\n",
        "cv  = CountVectorizer(ngram_range = (2,2))\n",
        "\n",
        "x = contents[\"Sentence(news)\"]\n",
        "X = cv.fit_transform(x).toarray()\n",
        "X\n",
        "y = contents[\"News_status\"]"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKT8gA9Lkozr"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktV3BnaLkqjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23c5b1e-0846-4baf-805c-0b189387f925"
      },
      "source": [
        "X_trainn = np.array(X_train)\n",
        "X_trainn.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39, 462)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDazO4ofk0xR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8051808e-16cd-42ac-afc1-7049a1e01cdd"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape (39, 462)\n",
            "y_train shape (39,)\n",
            "y_test shape (5,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8GpGS14k3Xs"
      },
      "source": [
        "X_train = X_train.reshape(len(X_train), X[1].size)\n",
        "X_test = X_test.reshape(len(X_test), X[1].size)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhPISLW1k7TL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc02788-c3b9-41fc-f354-ef82d42213d6"
      },
      "source": [
        "from sklearn import svm\n",
        "classification  = svm.SVC()\n",
        "classification.fit(X_train, y_train)\n",
        "pred = classification.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(pred, y_test)\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIhb33bfi5Mm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "eadd7044-98fa-49d8-afa7-8262ac623944"
      },
      "source": [
        "# N-Grams, Implementation of Bi Grams\n",
        "\"\"\"\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv  = CountVectorizer(ngram_range = (2,2))\n",
        "corpus = [\"This is a first sentence\",\n",
        "          \"This is an another sentence\",\n",
        "          \"that the third sentence\"]\n",
        "\n",
        "X = cv.fit_transform(corpus)\n",
        "print(X.shape)\n",
        "print(X.toarray())\n",
        "\n",
        "df = pd.DataFrame(X.toarray(), columns = cv.get_feature_names())\n",
        "print(df)\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom sklearn.feature_extraction.text import CountVectorizer\\ncv  = CountVectorizer(ngram_range = (2,2))\\ncorpus = [\"This is a first sentence\",\\n          \"This is an another sentence\",\\n          \"that the third sentence\"]\\n\\nX = cv.fit_transform(corpus)\\nprint(X.shape)\\nprint(X.toarray())\\n\\ndf = pd.DataFrame(X.toarray(), columns = cv.get_feature_names())\\nprint(df)\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X-dixP4UGdd"
      },
      "source": [
        ""
      ],
      "execution_count": 93,
      "outputs": []
    }
  ]
}